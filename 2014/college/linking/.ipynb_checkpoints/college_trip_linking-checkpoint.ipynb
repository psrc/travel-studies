{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linking trips for 2014 college travel study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 20)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# person = pd.read_csv(r'J:\\Projects\\Surveys\\HHTravel\\Survey2014\\Data\\Final database\\College\\2014-pr1-college-persons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trip_person = trip.merge(person, left_on='personID', right_on='personid')\n",
    "# len(trip_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trip_person.groupby('mode').count()['expwt'].to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "working_dir = r'J:\\Projects\\Surveys\\HHTravel\\Survey2014\\Data\\Final database\\College\\Linked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saved the xlsx as a CSV for quicker loading into pandas\n",
    "unlinked_trips = working_dir + r'\\2014-pr1-college-trips-UNLINKED.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py:1170: DtypeWarning: Columns (16,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n"
     ]
    }
   ],
   "source": [
    "# Read the unlinked trips into df\n",
    "unlinked_df = pd.read_csv(unlinked_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20903"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3052.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlinked_df['gdist'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# renaming unlinked_df to trip for consistency with older code\n",
    "trip = unlinked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of unique personIDs\n",
    "uniquePersonIDs = trip.groupby('personID').count().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop through each person in the survey and extract trips that could require linking\n",
    "\n",
    "# Ignore trips that are drop-off/pick-up. These might indicate a mode change (SOV to HOV 2 or 3+) but we\n",
    "# don't want them to be linked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For some reason we have a person counter\n",
    "# Ignoring this on this script for now...\n",
    "# person_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of keywords to search for in destinations\n",
    "transit_keywords = pd.read_csv('transit_end_keywords.csv',header=None)\n",
    "transit_keywords =np.array(transit_keywords[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of keywords we want to search for to find trips that end at bus stops\n",
    "# these suggest there was some other dsetination besides a bus transfer and trips should be linked\n",
    "# transit_dest = ['BUS STOP', 'AUBURN TRAIN STATION', 'TRAIN', 'SOUNDER TRAIN', 'LAKEWOOD TRAIN STATION',\n",
    "#                'SEATTLE AMTRAK - KING STREET STATION', 'BELLEVUE TRANSIT CENTER', \n",
    "#                'RENTON TRANSIT CENTER', 'TRANSIT CENTER', 'LAKEWOOD TRANSIT CENTER', \n",
    "#                'TACOMA DOME TRANSIT CENTER', 'WESTLAKE TRANSIT CENTER', 'NORTHGATE TRANSIT CENTER',\n",
    "#                'LYNNWOOD TRANSIT CENTER', 'REDMOND TRANSIT CENTER', 'REDMOND TRANSIT CENTER VIA BUS',\n",
    "#                'CONVENTION TRANSIT CENTER', 'METRO TRANSIT/LINK', 'ISSAQUAH TRANSIT CENTER',\n",
    "#                'FEDERAL WAY TRANSIT CENTER', 'TACOMA DOME ON SOUND TRANSIT 586', \n",
    "#                 'CONVENTION CENTER TRANSIT STATION', 'DOWNTOWN SEATTLE TRANSIT TUNNEL',\n",
    "#                'NORTHGATE TRANSIT', 'KENMORE TRANSIT CENTER', 'CONVENTION PLACE TRANSIT CENTER',\n",
    "#                'BELLEVUE TRANSIT', 'ASH WAY TRANSIT CENTER', 'TRANSIT', 'MOUNT BAKE TRANSIT CENTER',\n",
    "#                'TACOMA DOME STATION', 'UNIVERSITY STREET TUNNEL STATION','SUMNER SOUNDER STATION',\n",
    "#                'KING STREET STATION','PIONEER SQUARE STATION', 'INTERNATIONAL DISTRICT TUNNEL STATION',\n",
    "#                'MONTLAKE FREEWAY STATION', 'COLUMBIA CITY LIGHT RAIL STATION', 'WESTLAKE STATION',\n",
    "#                'SOUNDER STATION', 'PUYALLUP STATION', 'UNION STATION', 'WESTLAKE STATION', \n",
    "#                'KENT STATION', 'PIONEER STREET TUNNEL STATION', 'AUBURN STATION',\n",
    "#                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(transit_dest).to_csv('transit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:2915: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  inplace=inplace, kind=kind, na_position=na_position)\n"
     ]
    }
   ],
   "source": [
    "# We will store the potentially unlinked trips in an array to evaluate later\n",
    "problem_trips = []\n",
    "\n",
    "for person in uniquePersonIDs:\n",
    "    \n",
    "    flag = 1    # keep track of each set of unlinked trips; people can have more than 1 in the survey\n",
    "    # Extract each persons' trips\n",
    "    trip_subsample = trip.query(\"personID == \" + str(person))\n",
    "    \n",
    "    # Ignore people who use the same mode for all trips\n",
    "    # Note that \"set\" retrieves all the unique collections of elements\n",
    "    # In this case we only want to evaluate a person's trips if their\n",
    "    # set of modes is greater than 1 (i.e., more than 1 mode is used during survey)\n",
    "    \n",
    "    # Make sure the trip subsample is sorted\n",
    "    trip_subsample.sort('tripnum',inplace=True)\n",
    "    \n",
    "    if len(set(trip_subsample['mode'])) > 1:   # len(set())  \n",
    "        \n",
    "        # Loop through each person's trips, compare one trip to its following trip\n",
    "        for row in xrange(0, len(trip_subsample)-1):\n",
    "            person_trip = trip_subsample.iloc[row]       \n",
    "            next_pers_trip = trip_subsample.iloc[row+1]\n",
    "            \n",
    "            # Compare the two trips to see if they should be linked\n",
    "            # Several different logical operators are used simultaneously as follows:\n",
    "            \n",
    "            # Ignore drop-off/pick-up trips. \n",
    "            # These might indicate a mode change (SOV to HOV 2 or 3+) but they are a legitimate trip purpose. \n",
    "            \n",
    "            # Flag trips that meet certain characteristics as candidates for trip linking:\n",
    "            if (    ((person_trip['mode'] <> next_pers_trip['mode'])          # Flag if the mode changes\n",
    "                or  (person_trip['mode'] == next_pers_trip['mode'] == 8)    # Flag if bus-to-bus transfer\n",
    "                or  (person_trip['mode'] == next_pers_trip['mode'] == 9))   # Flag if train-to-train transfer\n",
    "                and person_trip['a_dur'] <= 15                              # Flag if time spent between trips is under 15 min.\n",
    "                and (   person_trip['d_purpose'] == next_pers_trip['d_purpose']     # Flag if trip purpose is the same\n",
    "                     or person_trip['d_purpose'] == 15)                     # flag if purpose listed as \"mode change\"\n",
    "                and person_trip['d_purpose'] <> 9                           # Exclude if drop-off/pick-up trip purpose\n",
    "                or (person_trip['d_purpose'] == 15 and next_pers_trip['mode'] <> 16)  # Include all mode changes except planes\n",
    "                or (person_trip['place_end'] in transit_keywords)    # include all trips ending at a transit stop\n",
    "                ):\n",
    "                \n",
    "                    # If these conditions are met, add the trip to the problem_trips array for inspection\n",
    "                    problem_trips.append([str(person_trip['personID']) + \"%02d\" % (flag,), person_trip['tripID']])\n",
    "                    problem_trips.append([str(person_trip['personID']) + \"%02d\" % (flag,), next_pers_trip['tripID']])\n",
    "    \n",
    "            # After adding problem_trips, we reset the trip set index if needed\n",
    "            # We don't automatically reset this though because a trip might be \n",
    "            # a continuation of the preceeding unlinked trip pair.\n",
    "            # If the activity duration is longer 30 minutes, we assume it's a separate trip and increment the flag value\n",
    "            # The linked ID is no longer sequential but it is at least unique\n",
    "            if next_pers_trip['a_dur'] > 30 or next_pers_trip['place_end'] == 'HOME' or next_pers_trip['place_end'] == 'WORK':\n",
    "                flag += 1\n",
    "#     person_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In the problem_trips array, the first value is a concatentation of person ID in first 5 digits\n",
    "# and the last two digits represent the trip pair for that person.\n",
    "# For instance, one person might have multiple trips that need to be linked. In the first set\n",
    "# the last two digits in the first value would be 01, the 2nd trip set would be 02, etc.\n",
    "# A code of 3004803 represents the 3rd unlinked trip set for person 30048\n",
    "# The second value is the original tripID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3290 trips have issues and might need to be linked\n"
     ]
    }
   ],
   "source": [
    "print str(len(problem_trips)) + ' trips have issues and might need to be linked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join the regular trip file attributes to the problem trips, basedo n TripID\n",
    "problem_trips_df = pd.DataFrame(problem_trips,columns=['linked_flag', 'tripID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "# There are duplicates in the case where more than 2 trips are\n",
    "# flagged as unlinked - removed these\n",
    "# ex. trip 345 and 346 are flagged so they're both added to problem_trips\n",
    "# if 346 and 347 are also flagged, they are both added to problem_trips, leaving 2 copies of trip 346\n",
    "problem_trips_df = problem_trips_df.drop_duplicates(subset='tripID') \n",
    "problem_trips_df.fillna(0, inplace=True)\n",
    "\n",
    "problem_trips_df['tripID'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2854 trips now have issues after removing duplicates\n"
     ]
    }
   ],
   "source": [
    "print str(len(problem_trips_df)) + ' trips now have issues after removing duplicates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_trips = pd.merge(left=trip,right=problem_trips_df,on='tripID',left_index=True,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2854"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_unlinked_trips = trip[trip['tripID'].isin(merged_trips['tripID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2854"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_unlinked_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18049"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of all trips that will not be changed or removed during this process\n",
    "base_trips = trip[-trip['tripID'].isin(merged_trips['tripID'])]\n",
    "len(base_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unlinked_trips = merged_trips.query(\"linked_flag <> 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# List of all linked trip sets and the number of records in each\n",
    "unlinked_sets = pd.DataFrame(unlinked_trips.groupby('linked_flag').count()['tripID'])\n",
    "unlinked_sets['set_size'] = unlinked_sets['tripID']    # rename the set size column\n",
    "unlinked_sets['linked_flag'] = unlinked_sets.index    # keep the recordID value as a column so we can join it later\n",
    "unlinked_sets.reset_index(drop=True)\n",
    "print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Summary statistics on linked trip sets - gives us an idea of how well we identified linked trips\n",
    "setsize = {}\n",
    "for idx in list(unlinked_sets.index):\n",
    "     # Examine each set of linked trips\n",
    "     trip_set = unlinked_trips[unlinked_trips['linked_flag'] == idx]\n",
    "     setsize[idx] = len(trip_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find distribution of set sizes\n",
    "df_setsize = pd.DataFrame([setsize.keys(), setsize.values()]).T\n",
    "df_setsize.index = df_setsize[0]    # Set index equal to the set ID\n",
    "\n",
    "setsize_dist = df_setsize.groupby(1).count()   # Distribution of set size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "1     \n",
       "1    3\n",
       "2  868\n",
       "3  209\n",
       "4   78\n",
       "5   24\n",
       "6    7\n",
       "7    2"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setsize_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Distribution shows that most (90%) of sets are 2 or 3 trips only. \n",
    "# Let's automate join for the 2-trip sets and do the others manually. \n",
    "# Discard sets with more than 2 trips because these are too unusual\n",
    "\n",
    "# save the unlinked trip sets with more than 2 trips to edit manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9, \n",
       "            ...\n",
       "            2844, 2845, 2846, 2847, 2848, 2849, 2850, 2851, 2852, 2853],\n",
       "           dtype='int64', length=2854)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the set size value to the unlinked_trip df so we can filter out the trips associated with\n",
    "# sets with more than 2 trips that need to be linked\n",
    "unlinked_trips_new = unlinked_trips.merge(unlinked_sets, on='linked_flag')\n",
    "unlinked_trips_new.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1191"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unlinked_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18049"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlinked_trips_3_plus = unlinked_trips_new.query('set_size > 2')\n",
    "len(unlinked_trips_3_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(unlinked_trips_3_plus['tripnum'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# export to a csv\n",
    "# first sort by the trip ID so trips are in order\n",
    "unlinked_trips_3_plus['tripID_x'] = unlinked_trips_3_plus['tripID_x'].astype('int')\n",
    "unlinked_trips_3_plus.sort('tripID_x',ascending=True,inplace=True)\n",
    "unlinked_trips_3_plus.to_csv('unlinked-trips-3-plus-sets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordID</th>\n",
       "      <th>personID</th>\n",
       "      <th>tripID_x</th>\n",
       "      <th>tripnum</th>\n",
       "      <th>total_trip</th>\n",
       "      <th>Last</th>\n",
       "      <th>college</th>\n",
       "      <th>place_start</th>\n",
       "      <th>place_end</th>\n",
       "      <th>olat</th>\n",
       "      <th>...</th>\n",
       "      <th>transitline1</th>\n",
       "      <th>transitline2</th>\n",
       "      <th>transitline3</th>\n",
       "      <th>transitline4</th>\n",
       "      <th>transitline5</th>\n",
       "      <th>transitline6</th>\n",
       "      <th>mode_old</th>\n",
       "      <th>traveldate</th>\n",
       "      <th>linked_flag</th>\n",
       "      <th>tripID_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set_size</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>68</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>...</td>\n",
       "      <td>252</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "      <td>26</td>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>11</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          recordID  personID  tripID_x  tripnum  total_trip  Last  college  \\\n",
       "set_size                                                                     \n",
       "3              627       627       627      627         627    68      627   \n",
       "4              312       312       312      312         312    26      312   \n",
       "5              120       120       120      120         120    11      120   \n",
       "6               42        42        42       42          42     1       42   \n",
       "7               14        14        14       14          14     0       14   \n",
       "\n",
       "          place_start  place_end  olat    ...     transitline1  transitline2  \\\n",
       "set_size                                  ...                                  \n",
       "3                 627        627   627    ...              252             7   \n",
       "4                 312        312   312    ...              140             3   \n",
       "5                 120        120   120    ...               59             1   \n",
       "6                  42         42    42    ...               18             2   \n",
       "7                  14         14    14    ...                7             0   \n",
       "\n",
       "          transitline3  transitline4  transitline5  transitline6  mode_old  \\\n",
       "set_size                                                                     \n",
       "3                    0             0             0             0       627   \n",
       "4                    1             0             0             0       312   \n",
       "5                    1             0             0             0       120   \n",
       "6                    0             0             0             0        42   \n",
       "7                    0             0             0             0        14   \n",
       "\n",
       "          traveldate  linked_flag  tripID_y  \n",
       "set_size                                     \n",
       "3                627          627       627  \n",
       "4                312          312       312  \n",
       "5                120          120       120  \n",
       "6                 42           42        42  \n",
       "7                 14           14        14  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlinked_trips_3_plus.groupby('set_size').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2854"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unlinked_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the trips that are 2 trips only and join those\n",
    "unlinked_trips_df = unlinked_trips_new.query('set_size <= 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1739"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unlinked_trips_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reindex the df using linked_flag ID, so we can group results according to linked trip sets\n",
    "unlinked_trips_df.index = unlinked_trips_df.linked_flag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "linked_flag\n",
       "30277001    16-3\n",
       "30277001    16-3\n",
       "30310702     1-7\n",
       "30310702     1-7\n",
       "30182803     3-1\n",
       "30182803     3-1\n",
       "30234201     1-3\n",
       "30234201     1-3\n",
       "30399401     1-7\n",
       "30399401     1-7\n",
       "            ... \n",
       "30421604     1-3\n",
       "30442303     1-7\n",
       "30442303     1-7\n",
       "30290403     7-7\n",
       "30290403     7-7\n",
       "30124102     1-7\n",
       "30124102     1-7\n",
       "30038401     6-7\n",
       "30038401     6-7\n",
       "30297702       7\n",
       "Name: combined_modes, dtype: object"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new column with concatentation of modes used in each trip set\n",
    "\n",
    " # Convert from float to int first\n",
    "unlinked_trips_df['mode'] = unlinked_trips_df['mode'].astype(\"int64\")  \n",
    "\n",
    "# Convert to string\n",
    "unlinked_trips_df['mode'] = pd.DataFrame(unlinked_trips_df['mode'].astype(\"str\"))     \n",
    "\n",
    "unlinked_trips_df['combined_modes'] = unlinked_trips_df.groupby('linked_flag').apply(lambda x: '-'.join(x['mode']))\n",
    "unlinked_trips_df['combined_modes'].astype('str',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine and process the trips\n",
    "# Some metrics need to be added, others will inherit from the first or last trip in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sum required for these values\n",
    "sum_fields = ['gdist', 'gtime', 'trip_dur_reported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take the maximum value of a trip set for the following values\n",
    "max_fields = ['taxi_type', 'taxi_fare', 'vehicle', 'driver', 'toll', 'pool_start', 'park_off', 'park_campus_area',\n",
    "              'park_campus_lot', 'bikeshare', 'change_vehicles', 'park', 'mode_acc', 'mode_egr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert NA to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-254-891a1e18d25b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert transitline data into integer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'transitline'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0munlinked_trips_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munlinked_trips_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"int\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, raise_on_error, **kwargs)\u001b[0m\n\u001b[0;32m   2409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2410\u001b[0m         mgr = self._data.astype(\n\u001b[1;32m-> 2411\u001b[1;33m             dtype=dtype, copy=copy, raise_on_error=raise_on_error, **kwargs)\n\u001b[0m\u001b[0;32m   2412\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m   2502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2503\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2504\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'astype'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2506\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, **kwargs)\u001b[0m\n\u001b[0;32m   2457\u001b[0m                                                  copy=align_copy)\n\u001b[0;32m   2458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2459\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2461\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, raise_on_error, values, **kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         return self._astype(dtype, copy=copy, raise_on_error=raise_on_error,\n\u001b[1;32m--> 373\u001b[1;33m                             values=values, **kwargs)\n\u001b[0m\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m     def _astype(self, dtype, copy=False, raise_on_error=True, values=None,\n",
      "\u001b[1;32mc:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, raise_on_error, values, klass, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_astype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             newb = make_block(values,\n",
      "\u001b[1;32mc:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\core\\common.pyc\u001b[0m in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy)\u001b[0m\n\u001b[0;32m   2726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2727\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2728\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot convert NA to integer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2729\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2730\u001b[0m         \u001b[1;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert NA to integer"
     ]
    }
   ],
   "source": [
    "# Convert transitline data into integer\n",
    "for field in ['transitline' + str(x) for x in xrange(1,5)]:\n",
    "    unlinked_trips_df[field] = unlinked_trips_df[field].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the sums and max values of trips grouped by each person's set\n",
    "sums = unlinked_trips_df.groupby('linked_flag').sum()\n",
    "maxes = unlinked_trips_df.groupby('linked_flag').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we want to squish those unlinked trips together!\n",
    "# The \"primary trip\" will inherit characeristics of associated trips\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the trip ID of the longest trip in each set\n",
    "# pandas requires us to make a copy of the unlinked_trips_df to work with for technical reasons\n",
    "df = pd.DataFrame(unlinked_trips_df)\n",
    "df.index = unlinked_trips_df['tripID_x']    # confirm that the index is set to the trip ID\n",
    "\n",
    "# This call returns the index of the longest trip within each unique trip set\n",
    "primary_trips = pd.DataFrame(df.groupby('linked_flag')['gdist'].agg(lambda x: x.idxmax()))\n",
    "\n",
    "# The response is a bit unusual, but the single 'gdist' column contains the\n",
    "# tripID of the trip with the longest gdist value for each trip set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the list of trip IDs to select full trip data and create the \"primary trip\" df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-255-62ac502bccbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Select only the primary trip from each set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprimary_trips_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munlinked_trips_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tripID_x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprimary_trips\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gdist'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Select only the primary trip from each set\n",
    "primary_trips_df = unlinked_trips_df[df['tripID_x'].isin(primary_trips['gdist'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'primary_trips_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-256-0ab8f157d22e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Reset index to trip set ID\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprimary_trips_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprimary_trips_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinked_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'primary_trips_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Reset index to trip set ID \n",
    "primary_trips_df.index = primary_trips_df.linked_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'primary_trips_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-257-aee702ad087e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprimary_trips_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'primary_trips_df' is not defined"
     ]
    }
   ],
   "source": [
    "primary_trips_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-258-e63147d2144c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m               'cnty_start', 'zip_start', 'state_start', 'address_start', 'olat', 'olng']:\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#primary_trips_df.loc[:,field + '_original'] = primary_trips_df[field]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mprimary_trips_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'linked_flag'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# locate first trip in set [0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Change primary trip start information to that of first in linked trip set\n",
    "# Use the first trip's origin purpose (o_purpose)\n",
    "for field in ['time_start_mam', 'time_start_hhmm', 'o_purpose', 'place_start', 'city_start', \n",
    "              'cnty_start', 'zip_start', 'state_start', 'address_start', 'olat', 'olng']:\n",
    "    #primary_trips_df.loc[:,field + '_original'] = primary_trips_df[field]\n",
    "    primary_trips_df.loc[:,field] = df.groupby('linked_flag').apply(lambda x: x[field].iloc[0])    # locate first trip in set [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-259-6be46794a706>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Save the original data in a new column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#primary_trips_df.loc[:,field + '_original'] = primary_trips_df[field]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mprimary_trips_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'linked_flag'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# locate last trip in set [-1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Change primary trip end time to that of the last trip in the linked trip set\n",
    "# Use the activity duration and pupose from the last trip in the set, assuming this is the true intended trip purpose at destination\n",
    "for field in ['time_end_hhmm', 'time_end_hhmm', 'a_dur', 'd_purpose', 'place_end', \n",
    "              'city_end', 'cnty_end', 'zip_end','state_end', 'address_end', 'dlat', 'dlng']:\n",
    "    # Save the original data in a new column\n",
    "    #primary_trips_df.loc[:,field + '_original'] = primary_trips_df[field]\n",
    "    primary_trips_df.loc[:,field] = df.groupby('linked_flag').apply(lambda x: x[field].iloc[-1])   # locate last trip in set [-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sums' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-260-d45437671856>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Save original primary trip info in a new column appened with \"_original\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#primary_trips_df.loc[:,field + '_original'] = primary_trips_df[field]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprimary_trips_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msums\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sums' is not defined"
     ]
    }
   ],
   "source": [
    "# Replace the primary trip fields with summed data for fields we want to add over all trips in a set (distance, time, duration)\n",
    "for field in sum_fields:\n",
    "    # Save original primary trip info in a new column appened with \"_original\"\n",
    "    #primary_trips_df.loc[:,field + '_original'] = primary_trips_df[field]\n",
    "    primary_trips_df.loc[:,field] = sums[field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'maxes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-261-01210f9c9bc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Save original primary trip info in a new column appened with \"_original\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#primary_trips_df.loc[:,field + '_original'] = primary_trips_df[field]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mprimary_trips_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'maxes' is not defined"
     ]
    }
   ],
   "source": [
    "# Replace the primary trip fields with the \"max\" data from the trip set\n",
    "# Will catch any instance of taxi use, driver/passenger designation, tolls paid, carpooling, park and ride,\n",
    "# vehicle changes, parking, and transit access mode\n",
    "for field in max_fields:\n",
    "    # Save original primary trip info in a new column appened with \"_original\"\n",
    "    #primary_trips_df.loc[:,field + '_original'] = primary_trips_df[field]\n",
    "    primary_trips_df.loc[:,field] = maxes[field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-262-c9ef5580e69b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Combine information about the transit lines and transit systems used during the trip set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtr1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'linked_flag'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transitline1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'linked_flag'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transitline2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtr3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'linked_flag'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transitline3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtr4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'linked_flag'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transitline4'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Combine information about the transit lines and transit systems used during the trip set\n",
    "tr1 = pd.DataFrame(df.groupby('linked_flag')[['transitline1']].agg(lambda x: x.tolist()))\n",
    "tr2 = pd.DataFrame(df.groupby('linked_flag')[['transitline2']].agg(lambda x: x.tolist()))\n",
    "tr3 = pd.DataFrame(df.groupby('linked_flag')[['transitline3']].agg(lambda x: x.tolist()))\n",
    "tr4 = pd.DataFrame(df.groupby('linked_flag')[['transitline4']].agg(lambda x: x.tolist()))\n",
    "ts1 = pd.DataFrame(df.groupby('linked_flag')[['transitsystem1']].agg(lambda x: x.tolist()))\n",
    "ts2 = pd.DataFrame(df.groupby('linked_flag')[['transitsystem2']].agg(lambda x: x.tolist()))\n",
    "ts3 = pd.DataFrame(df.groupby('linked_flag')[['transitsystem3']].agg(lambda x: x.tolist()))\n",
    "ts4 = pd.DataFrame(df.groupby('linked_flag')[['transitsystem4']].agg(lambda x: x.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-263-2c1de982d88a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Concatenate the transitline values (1 through 4)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcombined_transitlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transitline1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtr2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transitline2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtr3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transitline3'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtr4\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transitline4'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcombined_transitsys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transitsystem1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mts2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transitsystem2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mts3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transitsystem3'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mts4\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transitsystem4'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#combined_transitlines[0].iloc[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tr1' is not defined"
     ]
    }
   ],
   "source": [
    "# Concatenate the transitline values (1 through 4)\n",
    "combined_transitlines = pd.DataFrame(tr1['transitline1'] + tr2['transitline2'] + tr3['transitline3'] + tr4['transitline4'])\n",
    "combined_transitsys = pd.DataFrame(ts1['transitsystem1'] + ts2['transitsystem2'] + ts3['transitsystem3'] + ts4['transitsystem4'])\n",
    "#combined_transitlines[0].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_transitlines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-264-5d4940fd5f72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create empty placeholder columns to be filled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcombined_transitlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tr1\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcombined_transitlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tr2\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcombined_transitlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tr3\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcombined_transitlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tr4\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'combined_transitlines' is not defined"
     ]
    }
   ],
   "source": [
    "# Create empty placeholder columns to be filled\n",
    "combined_transitlines[\"tr1\"] = \"\"\n",
    "combined_transitlines[\"tr2\"] = \"\"\n",
    "combined_transitlines[\"tr3\"] = \"\"\n",
    "combined_transitlines[\"tr4\"] = \"\"\n",
    "combined_transitsys[\"ts1\"] = \"\"\n",
    "combined_transitsys[\"ts2\"] = \"\"\n",
    "combined_transitsys[\"ts3\"] = \"\"\n",
    "combined_transitsys[\"ts4\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of columns for transit lines or transit systems (4 in 2014 survey design)\n",
    "num_transitlines = 4\n",
    "num_transys = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll need this call - creates a unique ordered list!\n",
    "def unique_ordered_list(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [ x for x in seq if not (x in seen or seen_add(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_transitlines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-267-d4a4ba049d6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_transitlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Add all unlinked trips' transitline data into a list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcombined_transitlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_ordered_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_transitlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#[0] selects the first column (which contains a concatenated list of all all lines used)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcombined_transitsys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_ordered_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_transitsys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#[0] selects the first column\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Remove zeros that might be at beginning of the list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'combined_transitlines' is not defined"
     ]
    }
   ],
   "source": [
    "for row in xrange(0, len(combined_transitlines)):\n",
    "    # Add all unlinked trips' transitline data into a list\n",
    "    combined_transitlines[0].iloc[row] = unique_ordered_list(combined_transitlines[0].iloc[row])  #[0] selects the first column (which contains a concatenated list of all all lines used)\n",
    "    combined_transitsys[0].iloc[row] = unique_ordered_list(combined_transitsys[0].iloc[row])  #[0] selects the first column\n",
    "    # Remove zeros that might be at beginning of the list\n",
    "    combined_transitlines[0].iloc[row] = [x for x in combined_transitlines[0].iloc[row] if x != 0]\n",
    "    combined_transitsys[0].iloc[row] = [x for x in combined_transitsys[0].iloc[row] if x != 0]\n",
    "    # But we want to pad the rest with zeros for consistent array shape\n",
    "    combined_transitlines[0].iloc[row] = np.pad(combined_transitlines[0].iloc[row],\n",
    "                                                (0,num_transitlines-len(combined_transitlines[0].iloc[row])),\n",
    "                                                mode='constant')\n",
    "    combined_transitsys[0].iloc[row] = np.pad(combined_transitsys[0].iloc[row],\n",
    "                                                (0,num_transitlines-len(combined_transitsys[0].iloc[row])),\n",
    "                                                mode='constant')\n",
    "\n",
    "    for i in xrange(4):\n",
    "        combined_transitlines[\"tr\" + str(i + 1)].iloc[row] = combined_transitlines[0].iloc[row][i]\n",
    "        combined_transitsys[\"ts\" + str(i + 1)].iloc[row] = combined_transitsys[0].iloc[row][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_transitlines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-268-240c4307b467>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Add the transitline values to the primary trip record\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprimary_trips_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transitline'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombined_transitlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tr'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprimary_trips_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transitsystem'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombined_transitsys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ts'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'combined_transitlines' is not defined"
     ]
    }
   ],
   "source": [
    "# Add the transitline values to the primary trip record\n",
    "for i in xrange(1,5):\n",
    "    primary_trips_df['transitline' + str(i)] = combined_transitlines['tr' + str(i)]\n",
    "    primary_trips_df['transitsystem' + str(i)] = combined_transitsys['ts' + str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trip_unlinked_removed_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-269-62628ca660fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Trips with all linked trips added (and unlinked trips removed)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrip_with_linked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrip_unlinked_removed_all\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprimary_trips_df\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'trip_unlinked_removed_all' is not defined"
     ]
    }
   ],
   "source": [
    "# Trips with all linked trips added (and unlinked trips removed)\n",
    "trip_with_linked = pd.concat([trip_unlinked_removed_all,primary_trips_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'primary_trips_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-270-d9b74cc703df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Distribution of combined trip modes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprimary_trips_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'combined_modes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'recordID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'recordID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# shows most trips are walk-walk, bus-bus, bus-walk...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'primary_trips_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Distribution of combined trip modes\n",
    "a = pd.DataFrame(primary_trips_df.groupby('combined_modes').count()['recordID'])\n",
    "a.sort('recordID', ascending=False, inplace=True)\n",
    "a\n",
    "# shows most trips are walk-walk, bus-bus, bus-walk..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trip_with_linked' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-271-0f3fec43fa16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Add the count of unlinked trips in each linked trip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrip_with_linked\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'num_trips_linked'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_setsize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'trip_with_linked' is not defined"
     ]
    }
   ],
   "source": [
    "# Add the count of unlinked trips in each linked trip \n",
    "trip_with_linked['num_trips_linked'] = df_setsize[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unlinked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'primary_trips_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-273-befe6016e611>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Linked Trips only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Join with regular trip file data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprimary_trips_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'combined_modes'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"'\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mprimary_trips_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'combined_modes'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprimary_trips_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'completed_linked_trips.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'primary_trips_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Linked Trips only\n",
    "# Join with regular trip file data\n",
    "primary_trips_df['combined_modes'] = \"'\" + primary_trips_df['combined_modes'] + \"'\"\n",
    "primary_trips_df.to_csv('completed_linked_trips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Brice\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\IPython\\kernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from IPython.kernel.zmq import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Unlinked Trips only (2 trip sets)\n",
    "unlinked_trips_df['combined_modes'] = \"'\" + unlinked_trips_df['combined_modes'] + \"'\"\n",
    "unlinked_trips_df.to_csv('unlinked_trips_setsize2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unlinked Trips only (3+ trip sets)\n",
    "unlinked_trips_3_plus.to_csv('unlinked_trips_setsize3plus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are all the trips that are not part of linked sets\n",
    "base_trips.to_csv(\"base_trips.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2854"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unlinked_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
